\include{preamble}
\begin{document}
\maketitle

\begin{abstract}
Systematic reviewing is a technique for bringing scientific rigour to a computer science literature review, pioneered by Barbara Kitchenham~\citep{Kitchenham2004}. Specifically, Kitchenham's systematic reviews utilise concepts from the field of medical research to create literature reviews which are repeatable, and produce statistical and empirical results. 12 years after Kitchenham's original guidelines were set for structuring a systematic literature review, the technique has seen widespread adoption --- but the original guidelines raise questions and note possible issues with the method. With a wide set of samples to choose from, a review of these systematic reviews may highlight whether these concerns are worth revisiting, before Kitchenham's guidelines --- or other methods derived from them --- become standard practice for the software engineering research community.
\end{abstract}

\section{Introduction}
% Explore what a systematic review is, and why we're exploring them as a topic.
A Systematic Review is a literature review which collates the results of many papers, using statistical analysis to draw empirical results about the state of a research field and to answer research questions posited as the motivation for the review. Systematic reviews are born from the philosophy that a literature review should have scientific merit, and produce reproducible results, rather than standard techniques for literature reviews, which leave more room for subjective insight. The scientific nature of a systematic literature review, in theory, removes ambiguity and bias from literature review practice and lends the review the same validity and credence as a research study.\par

% Introduce the notion that there's a problem with the technique --- bring up the original guidelines.
Kitchenham's systematic literature review technique has begun to dominate as a literature review technique for software engineering. Kitchenham's review procedure stems largely from literature review techniques in medical research~\citep{Kitchenham2004, khan2001undertaking}, where empirical studies which verify the validity of literature already published in peer-reviewed journals is paramount to civilian safety. Conventional computing science literature reviews might closer resemble Webster's guidelines~\citep{Webster2002}, which are less rigorous, and less focused on empiricism and repeatability. While the technique has seen widespread adoption, some issues exist with the implementation --- as noted by Kitchenham herself in a systematic review of systematic review procedures~\citep{Kitchenham2013}. More fundamentally, in Kitchenham's original guidelines there exist some notes which cast doubt on the suitability of a systematic review in the field of software engineering. For example:
\begin{displayquote}
    In particular, software engineering research has relatively little empirical research compared with the large quantities of research available on medical issues, and research methods used by software engineers are not as rigorous as those used by medical researchers.
\end{displayquote}
In her guidelines, Kitchenham provides types of empirical data which software engineering research \emph{does} produce which can be appropriate for analysis in a literature review. However, whether research rigour and types of data collected are make appropriate note of by the research community is clear only now that a wealth of systematic literature reviews have been produced.\par

% Whatcha doin?
In this review, a series of systematic literature reviews will be analysed and searched for their scrutiny of research rigour and format of empirical data. In this way, the importance of this doubt regarding the suitability of systematic reviews for software engineering research will be assessed.\par

The reviews chosen were picked as a result of their popularity on the ``\emph{Google Scholar}'' academic search engine, found by a search for ``software engineering ``systematic'' literature review'', and similar searches. This was to find papers which were well-cited and high-impact, because as the question to be answered would impact the culture around systematic reviews, these papers are important, as they are most likely to influence future systematic reviews.\par


\section{Papers reviewed}
\input{Kampanes_EffectSize}
\input{Smite_GSE}
\input{Benavides_Automated}
\input{Beecham_Motivation}


\section{Discussion}\label{sec:discussion}

% Worth pointing out that you can't subject a regular review to the same sort of scrutiny as a systematic review
% - At least you're guaranteed data and rigour as a reader
% - Maybe this is something semantic guidelines might be able to provide?

% Best thing we can say about all of these papers is that regardless of whether they use statistics, they're repeatable. 
% - Does repeatability matter in this case?
% - There may well be useful insight in the motivation case, for example, but simple counts of papers were presented instead. 
% - Results seem cursory this way --- never much food for thought, and a literature review is the best opportunity for thought food: someone's just read loads of papers and can tell us things we don't know about the field at large!

\section{Conclusion}

% Did the literature reviews matter?

% Things to note when writing this:
% - Do the literature reviews having ``systematic'' pedigree make them more susceptible to draw conclusions which aren't actually important? Can they get away with saying unimportant things, because the systematic review makes them sound more important?
% - Perhaps a systematic review should be something chosen only if a review turns out to produce lots of data to analyse? Should they necessarily start with rigour? If yes, how can we ensure more data of higher quality?


\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}
