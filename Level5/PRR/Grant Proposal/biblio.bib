@article{Urbano2014,
author = {Urbano, Joana and Rocha, Ana Paula and Oliveira, Eug{\'{e}}nio},
doi = {10.3233/AIC-130587},
file = {:Users/tom/Documents/Papers/An{\_}approach{\_}to{\_}computational{\_}social{\_}trus.pdf:pdf},
keywords = {agent-based systems,computational trust,social trust},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
pages = {113--131},
title = {{An approach to computational social trust}},
volume = {27},
year = {2014}
}
@article{Marsh1994,
abstract = {Trust is a judgement of unquestionable utility as humans we use it every day of our lives. However, trust has suffered from an imperfect understanding, a plethora of definitions, and informal use in the literature and in everyday life. It is common to say I trust you, but what does that mean? This thesis provides a clarification of trust. We present a formalism for trust which provides us with a tool for precise discussion. The formalism is implementable: it can be embedded in an artificial agent, enabling the agent to make trust-based decisions. Its applicability in the domain of Distributed Artificial Intelligence (DAI) is raised. The thesis presents a testbed populated by simple trusting agents which substantiates the utility of the formalism. The formalism provides a step in the direction of a proper understanding and definition of human trust. A contribution of the thesis is its detailed exploration of the possibilities of future work in the area.},
author = {Marsh, Stephen Paul},
doi = {10.2165/00128413-199409230-00010},
file = {:Users/tom/Documents/Papers/Formalising trust as a computational concept.pdf:pdf},
isbn = {CSM-133},
journal = {Computing},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
number = {April},
pages = {184},
title = {{Formalising Trust as a Computational Concept}},
volume = {Doctor of},
year = {1994}
}
@article{Lu2009,
abstract = {Trust plays important roles on effective interaction and cooperation for multi-agent systems(MAS). This study aims at finding out the current situation and future trends of computational trustfor multi-agent systems. Through defining seven common compositional elements for the computational trust models, the study points out significant weaknesses in the current design. Finally, the paper figures out the future research trends through discussion and analysis around the strengths and weaknesses identified. Also the paper proposes an idea of using ontology and XML technologies such as RDF that allow systems to provide both human and machine readable annotations for trust models.},
author = {Lu, Gehao and Lu, Joan and Yao, Shaowen and Yip, Jim},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Lu et al. - 2009 - A Review on Computational Trust Models for Multi-agent Systems.pdf:pdf},
journal = {The Open Information Science Journal},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
pages = {18--25},
title = {{A Review on Computational Trust Models for Multi-agent Systems}},
volume = {2},
year = {2009}
}
@article{Chandrasekaran2011,
abstract = {The lack of an universal model in reputation systems makes it challenging to evaluate and compare them against attacks. While there are test beds that provide application domain specific metrics to evaluate reputation systems, in this paper we propose a model for a test bed that is application agnostic. It is a workflow of graph transformations that is generic enough to accommodate a number of reputation systems in existing literature. In doing so, we note that these reputation systems work at different stages in the workflow and as a result, a byproduct of this model is a new classification method. We also describe various attacks using our model.},
author = {Chandrasekaran, Partheeban and Esfandiari, Babak},
doi = {10.1109/TrustCom.2011.40},
file = {:Users/tom/Documents/Papers/A{\_}Model{\_}For{\_}A{\_}Testbed{\_}For{\_}Evaluating{\_}Reputation{\_}Sy.pdf:pdf},
isbn = {9780769546001},
journal = {Proc. 10th IEEE Int. Conf. on Trust, Security and Privacy in Computing and Communications, TrustCom 2011, 8th IEEE Int. Conf. on Embedded Software and Systems, ICESS 2011, 6th Int. Conf. on FCST 2011},
keywords = {model,reputation systems,testbed},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
pages = {296--303},
title = {{A model for a testbed for evaluating reputation systems}},
year = {2011}
}
@article{Herzig2009,
abstract = {The aim of this paper is to present a logical framework in which the concepts of trust and reputation can be formally characterized and their properties studied. We start from the definition of trust proposed by Castelfranchi {\&} Falcone (C{\&}F). We formalize this definition in a logic of time, action, beliefs and choices. Then, we provide a refinement of C{\&}F's definition by distinguishing two general types of trust: occurrent trust and dispositional trust. In the second part of the paper we present a definition of reputation that is structurally similar to the definition of trust but moves the basic concept of belief to a collective dimension of group belief.},
author = {Herzig, Andreas and Lorini, Emiliano and H{\"{u}}bner, Jomi F. and Vercouter, Laurent},
doi = {10.1093/jigpal/jzp077},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Herzig et al. - 2009 - A logic of trust and reputation.pdf:pdf},
isbn = {13670751},
issn = {13670751},
journal = {Logic Journal of the IGPL},
keywords = {BDI logic,Belief,Goal,Group belief,Reputation,Trust},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{A logic of trust and reputation}},
year = {2009}
}
@inproceedings{Simpson2015,
abstract = {Modelling the structure of social-technical systems as a basis
for informing software system design is a difficult compromise. Formal
methods struggle to capture the scale and complexity of the hetero-
geneous organisations that use technical systems. Conversely, informal
approaches lack the rigour needed to inform the software design and
construction process or enable automated analysis.
We revisit the concept of responsibility modelling, which models social
technical systems as a collection of actors who discharge their responsibil-
ities, whilst using and producing resources in the process. Responsibility
modelling is formalised as a structured approach for socio-technical sys-
tem requirements specification and modelling, with well-defined seman-
tics and support for automated structure and validity analysis. The
effectiveness of the approach is demonstrated by two case studies of soft-
ware engineering methodologies.
},
author = {Simpson, Robbie and Storer, Tim},
booktitle = {Lecture Notes in Business Information Processing},
doi = {10.1007/978-3-319-24626-0_10},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Simpson, Storer - 2015 - Formalising responsibility modelling for automatic analysis.pdf:pdf},
isbn = {9783319246253},
issn = {18651348},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{Formalising responsibility modelling for automatic analysis}},
year = {2015}
}
@article{Hubner,
abstract = {Among the several categories of trust models, cognitive models have important features. Initially these models were only informally defined, but formalizations were recently proposed. The concepts of the models are thus sufficiently well defined to be implemented and evaluated. In this paper, the cognitive trust model proposed by Castelfranchi and Falcone is integrated into a BDI (belief, desire, intention) agent architecture and implemented with the Jason programming language. The ART testbed scenario is then used to experiment and evaluate both the model and the implementation.},
author = {H{\"{u}}bner, Jomi F and Lorini, Emiliano and Vercouter, Laurent and Herzig, Andreas},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/H{\"{u}}bner et al. - Unknown - From cognitive trust theories to computational trust.pdf:pdf},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{From cognitive trust theories to computational trust}}
}
@inproceedings{Castelfranchi1997,
author = {Castelfranchi, Cristiano and Falcone, Rino},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/3-540-63077-5_36},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Castelfranchi, Falcone - 1997 - Delegation conflicts.pdf:pdf},
isbn = {3540630775},
issn = {16113349},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{Delegation conflicts}},
year = {1997}
}
@article{Brewka,
abstract = {1.1 Introduction Classical logic is monotonic in the following sense: whenever a sentence A is a logical consequence of a set of sentences T , then A is also a consequence of an arbitrary superset of T . In other words, adding information never invalidates any conclusions. Commonsense reasoning is different. We often draw plausible conclusions based on the assumption that the world in which we function and about which we reason is normal and as expected. This is far from being irrational. To the contrary, it is the best we can do in situations in which we have only incomplete information. However, as unexpected as it may be, it can happen that our normality assumptions turn out to be wrong. New information can show that the situation actually is abnormal in some respect. In this case we may have to revise our conclusions. For example, let us assume that Professor Jones likes to have a good espresso after lunch in a campus caf{\'{e}}. You need to talk to her about a grant proposal. It is about 1:00pm and, under normal circumstances, Professor Jones sticks to her daily routine. Thus, you draw a plausible conclusion that she is presently enjoying her favorite drink. You decide to go to the caf{\'{e}} and meet her there. As you get near the student center, where the cafe is located, you see people streaming out of the building. One of them tells you about the fire alarm that just went off. The new piece of information invalidates the normality assumption and so the conclusion about the present location of Professor Jones, too. Such reasoning, where additional information may invalidate conclusions, is called nonmonotonic. It has been a focus of extensive studies by the knowledge representation community since the early eighties of the last century. This interest was fueled by several fundamental challenges facing knowledge representation such as modeling and reasoning about rules with exceptions or defaults, and solving the frame problem.},
author = {Brewka, Gerhard and Niemel{\"{a}}, Ilkka and Truszcz, Miros{\l}aw},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Brewka, Niemel{\"{a}}, Truszcz - Unknown - Nonmonotonic Reasoning.pdf:pdf},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{Nonmonotonic Reasoning}}
}
@article{Sandlewall,
author = {Sandlewall, Eric},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Sandlewall - Unknown - An Approach to the Frame Problem, and its Implementation.pdf:pdf},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{An Approach to the Frame Problem, and its Implementation}}
}
@article{Kramdi,
author = {Kramdi, Seifeddine},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Kramdi - 2015 - A modal approach to model computational trust.pdf:pdf},
journal = {PhD Thesis},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{A modal approach to model computational trust}},
url = {https://tel.archives-ouvertes.fr/tel-01328169},
year = {2015}
}
@article{Marsh2009,
author = {Marsh, Stephen and Briggs, Pamela},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Marsh, Briggs - 2009 - Examining trust, forgiveness and regret as computational concepts.pdf:pdf},
journal = {Computing with Social Trust},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{Examining trust, forgiveness
and regret as computational concepts}},
year = {2009}
}
@article{DeLima2008,
abstract = {One way to allocate tasks to agents is by ascribing them obligations. From obligations to be, agents are able to infer what are the forbidden, permitted and obligatory actions they may perform, by using the well-known Meyer's reduction from obligations to be to obligations to do. However, we show through an example that this method is not completely adequate to guide agents' decisions. We then propose a solution using, instead of obligations, the concept of 'responsibility'. To formalise re-sponsibility we use a multi-agent extension of propositional dynamic logic as framework, and then we define some basic concepts, such as 'agent ability', also briefly discussing the problem of uniform strategies and a possible solution. In the last part, we show that our framework can be used in the specification of normative multi-agent systems, by presenting an extensive running example.},
author = {{De Lima}, Tiago and Royakkers, Lam Er and Dignum, Frank},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/De Lima, Royakkers, Dignum - 2008 - A Logic for Reasoning about Responsibility.pdf:pdf},
keywords = {abilities,dynamic logic,normative multi-agent systems,obligations,responsibility},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{A Logic for Reasoning about Responsibility}},
year = {2008}
}
@book{Birkhoff1933,
author = {Birkhoff, George},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Birkhoff - 1933 - Aesthetic Measure.pdf:pdf},
keywords = {aesthetics,math,measure,metrics,music,ratios,vases},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
title = {{Aesthetic Measure }},
year = {1933}
}
@article{Castelfranchi2001,
abstract = {After arguing about the crucial importance of trust for Agents and MAS, we provide a definition of trust both as a mental state and as a social attitude and relation. We present the mental ingredients of trust: its specific beliefs and goals, with special attention to evaluations and expectations. We show the relation between trust and the mental background of delegation. We explain why trust is a bet, and implies some risks, and analyse the more complex forms of social trust, based on a theory of mind and in particular on morality, reputation and disposition, and authority (three party trust). We explain why promises, contracts, authorities can increase our trust by modifying our mental representations. We present a principled quantification of trust, based on its cognitive ingredients, and use this "degree of trust" as the basis for a rational decision to delegate or not to another agent. We explain when trust is rational, and why it is not an irrational decision by definition. We also criticise the economic and game-theoretic view of trust for underestimating the importance of cognitive ingredients of trust and for reducing it to subjective probability and risk. The paper is intended to contribute both to the conceptual analysis and to the practical use of trust in social theory and MAS.},
author = {Castelfranchi, Cristiano and Falcone, Rino},
doi = {10.1007/978-94-017-3614-5_3},
file = {:Users/tom/Documents/Papers/10.1.1.98.6870.pdf:pdf},
isbn = {079236919X},
journal = {Trust and deception in virtual societies},
mendeley-groups = {Computational Trust/Responsibility,PRR Literature Review},
pages = {55--90},
title = {{Social Trust : A Cognitive Approach}},
year = {2001}
}
@article{Kamvar2003,
abstract = {Peer-to-peer file-sharing networks are currently receiving much at- tention as a means of sharing and distributing information. How- ever, as recent experience shows, the anonymous, open nature of these networks offers an almost ideal environment for the spread of self-replicating inauthentic files. We describe an algorithm to decrease the number of downloads of inauthentic files in a peer-to-peer file-sharing network that as- signs each peer a unique global trust value, based on the peer's history of uploads. We present a distributed and secure method to compute global trust values, based on Power iteration. By having peers use these global trust values to choose the peers from whom they download, the network effectively identifies malicious peers and isolates them from the network. In simulations, this reputation system, called EigenTrust, has been shown to significantly decrease the number of inauthentic files on the network, even under a variety of conditions wheremalicious peers cooperate in an attempt to deliberately subvert the system.},
author = {Kamvar, Sepandar D and Schlosser, Mario T and Garcia-Molina, Hector},
doi = {10.1145/775240.775242},
file = {:Users/tom/Downloads/p640-kamvar.pdf:pdf},
isbn = {1581136803},
issn = {1581136803},
journal = {12th International Conference on World Wide Web (WWW )},
keywords = {distributed eigenvector computation,peer-to-peer,reputation},
pages = {640},
title = {{The Eigentrust algorithm for reputation management in P2P networks}},
url = {http://portal.acm.org/citation.cfm?doid=775152.775242},
year = {2003}
}
@article{deutsch1962cooperation,
  title={Cooperation and trust: Some theoretical notes.},
  author={Deutsch, Morton},
  year={1962},
  publisher={Univer. Nebraska Press}
}
@article{luhmann2000familiarity,
  title={Familiarity, confidence, trust: Problems and alternatives},
  author={Luhmann, Niklas},
  year={2000}
}
@article{deontic-logic,
 ISSN = {00264423, 14602113},
 author = {G. H. von Wright},
 journal = {Mind},
 number = {237},
 pages = {1-15},
 publisher = {[Oxford University Press, Mind Association]},
 title = {Deontic Logic},
 volume = {60},
 year = {1951}
}
@article{Sabater,
author = {Sabater, Jordi and Sierra, Carles},
file = {:Users/tom/Library/Application Support/Mendeley Desktop/Downloaded/Sabater, Sierra - Unknown - REGRET Reputation in gregarious societies.pdf:pdf},
isbn = {158113326X},
journal = {System},
title = {{REGRET: Reputation in gregarious societies}}
}
@incollection{Sommerville:2007ec,
author = {Sommerville, Ian},
title = {{Causal Responsibility Models}},
booktitle = {Responsibility and Dependable Systems},
year = {2007},
pages = {187--207},
publisher = {Springer London},
address = {London}
}
@unpublished{wallis2017,
  title={Investigating Computational Responsibility},
  year={2017},
  note = {MSci thesis, currently in progress.},
  author = {Tom Wallis}
}
@unpublished{wallis_x,
title= {Anthropomorphic Algorithms},
author = {Wallis, Tom},
year = {2017},
note= {Let's Talk About [X] --- \url{https://youtu.be/RGUeYQzRsOQ}},
URL= {\url{https://youtu.be/RGUeYQzRsOQ}},
}
@article{Crawford2013127,
title = "A framework for continuous, transparent mobile device authentication ",
journal = "Computers \& Security ",
volume = "39, Part B",
number = "",
pages = "127 - 136",
year = "2013",
note = "",
issn = "0167-4048",
doi = "http://dx.doi.org/10.1016/j.cose.2013.05.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167404813000886",
author = "Heather Crawford and Karen Renaud and Tim Storer",
keywords = "Authentication",
keywords = "Biometrics",
keywords = "Transparent",
keywords = "Framework",
keywords = "Mobile "
}
@inproceedings{nam2011conceptualizing,
  title={Conceptualizing smart city with dimensions of technology, people, and institutions},
  author={Nam, Taewoo and Pardo, Theresa A},
  booktitle={Proceedings of the 12th annual international digital government research conference: digital government innovation in challenging times},
  pages={282--291},
  year={2011},
  organization={ACM}
}
